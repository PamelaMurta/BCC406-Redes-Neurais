# ğŸ“‹ Resumo do Projeto - BCC406 Redes Neurais

## ğŸ¯ TÃ­tulo
**ComparaÃ§Ã£o entre Random Forest e CNN 1D para IdentificaÃ§Ã£o de Falantes**

---

## ğŸ“ DescriÃ§Ã£o

Projeto acadÃªmico da disciplina **BCC406 - Redes Neurais** que implementa e compara dois paradigmas de aprendizado de mÃ¡quina para a tarefa de **identificaÃ§Ã£o de falantes** em Ã¡udio:

### Modelos Comparados

| Modelo | Categoria | CaracterÃ­sticas |
|--------|-----------|-----------------|
| **Random Forest** | Machine Learning ClÃ¡ssico | - 100 Ã¡rvores de decisÃ£o<br>- Features agregadas (mÃ©dia, std, etc.)<br>- ~4000 features por amostra |
| **CNN 1D** | Deep Learning | - 3 blocos convolucionais<br>- BatchNorm + Dropout<br>- ~167,000 parÃ¢metros |

---

## ğŸ”¬ Metodologia

### 1. **Dataset**
- **Oficial:** VoxCeleb1 (~38GB, 1,251 falantes, ~100k arquivos)
- **Teste:** SintÃ©tico (200 arquivos, 10 falantes, ~180MB)

### 2. **Features**
- **MFCCs:** 40 coeficientes
- **Janela temporal:** 100 time steps
- **Formato:** (batch, 100, 40) para CNN | (batch, 4000) para RF

### 3. **Treinamento**
- **DivisÃ£o:** 60% treino, 20% validaÃ§Ã£o, 20% teste
- **Otimizador:** Adam (lr=0.001 para CNN)
- **Loss:** Categorical Crossentropy
- **MÃ©tricas:** AcurÃ¡cia, PrecisÃ£o, Recall, F1-Score

---

## ğŸ“Š Resultados

### Dataset SintÃ©tico (200 amostras)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Modelo          â”‚ AcurÃ¡cia â”‚ PrecisÃ£o â”‚ Recall  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Random Forest   â”‚  96.7%   â”‚  97.2%   â”‚  96.5%  â”‚
â”‚ CNN 1D          â”‚  66.7%   â”‚  68.3%   â”‚  66.1%  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ† Vencedor: Random Forest (+30% de diferenÃ§a)
```

**AnÃ¡lise:**
- RF superior em datasets pequenos (overfitting da CNN)
- CNN precisa de mais dados para generalizar
- RF mais interpretÃ¡vel e rÃ¡pido para treinar

### VoxCeleb1 Completo
*ğŸ”„ Treinamento pendente - resultados serÃ£o adicionados*

---

## ğŸ› ï¸ Tecnologias

### Core
- **Python:** 3.11.4
- **TensorFlow:** 2.14.0 (backend da CNN)
- **scikit-learn:** 1.3.0 (Random Forest)
- **librosa:** 0.10.1 (processamento de Ã¡udio)

### Suporte
- **NumPy:** 1.24.3
- **Pandas:** 2.0.3
- **Matplotlib:** 3.7.2
- **seaborn:** 0.12.2

**Total:** 15+ dependÃªncias (ver [requirements.txt](requirements.txt))

---

## ğŸ“ Estrutura do CÃ³digo

### **MÃ³dulos Principais** (`src/`)
```
src/
â”œâ”€â”€ data/dataset.py              # Gerenciamento de datasets
â”œâ”€â”€ features/audio_features.py   # ExtraÃ§Ã£o de MFCCs
â”œâ”€â”€ training/trainer.py          # Treinadores genÃ©ricos
â”œâ”€â”€ evaluation/metrics.py        # CÃ¡lculo de mÃ©tricas
â””â”€â”€ utils/helpers.py             # FunÃ§Ãµes auxiliares
```

### **Scripts ExecutÃ¡veis** (`scripts/`)
```
scripts/
â”œâ”€â”€ run_full_pipeline.py         # Pipeline completo
â”œâ”€â”€ train_rf.py                  # Treinar Random Forest
â”œâ”€â”€ train_cnn.py                 # Treinar CNN
â”œâ”€â”€ evaluate_models.py           # Avaliar ambos modelos
â”œâ”€â”€ baixar_voxceleb1.py          # Download VoxCeleb1
â””â”€â”€ generate_synthetic_data.py   # Gerar dados teste
```

### **Notebooks Jupyter** (`notebooks/`)
1. `01_exploratory_analysis.ipynb` - EDA dos dados
2. `02_feature_extraction.ipynb` - ExtraÃ§Ã£o de MFCCs
3. `03_random_forest_baseline.ipynb` - Baseline RF
4. `04_cnn_model.ipynb` - Modelo CNN
5. `05_comparative_analysis.ipynb` - AnÃ¡lise comparativa

---

## ğŸš€ Como Executar

### OpÃ§Ã£o 1: Pipeline Completo (Recomendado)
```bash
python scripts/run_full_pipeline.py
```
**Tempo:** ~5-10 minutos com dados sintÃ©ticos

### OpÃ§Ã£o 2: Google Colab
1. Abra [notebooks/COLAB_Pipeline_Completo.md](notebooks/COLAB_Pipeline_Completo.md)
2. Siga as instruÃ§Ãµes
3. Execute cÃ©lulas sequencialmente

### OpÃ§Ã£o 3: Passo a Passo
```bash
# 1. Gerar dados sintÃ©ticos
python scripts/generate_synthetic_data.py

# 2. Treinar Random Forest
python scripts/train_rf.py

# 3. Treinar CNN
python scripts/train_cnn.py

# 4. Avaliar e comparar
python scripts/evaluate_models.py
```

---

## ğŸ“š DocumentaÃ§Ã£o

### Por Perfil de UsuÃ¡rio

| Perfil | Documento | Foco |
|--------|-----------|------|
| **Iniciante** | [GUIA_RAPIDO.md](GUIA_RAPIDO.md) | Executar rapidamente |
| **Desenvolvedor** | [ESTRUTURA_DO_PROJETO.md](ESTRUTURA_DO_PROJETO.md) | Arquitetura do cÃ³digo |
| **Pesquisador** | [docs/metodologia.md](docs/metodologia.md) | Teoria e metodologia |
| **UsuÃ¡rio Colab** | [notebooks/COLAB_Pipeline_Completo.md](notebooks/COLAB_Pipeline_Completo.md) | Tutorial passo a passo |
| **Qualquer um** | [INDICE.md](INDICE.md) | Hub de navegaÃ§Ã£o |

---

## âœ… Funcionalidades Implementadas

### ExtraÃ§Ã£o de Features
- [x] MFCCs com librosa
- [x] NormalizaÃ§Ã£o de Ã¡udio
- [x] AgregaÃ§Ã£o estatÃ­stica (mÃ©dia, std, min, max)
- [x] Features sequenciais para CNN

### Modelos
- [x] Random Forest com tunning
- [x] CNN 1D com arquitetura customizada
- [x] Salvamento de modelos treinados
- [x] Carregamento de checkpoints

### AvaliaÃ§Ã£o
- [x] MÃ©tricas padrÃ£o (acurÃ¡cia, precisÃ£o, recall, F1)
- [x] Matriz de confusÃ£o
- [x] Curvas de aprendizado
- [x] ComparaÃ§Ã£o lado a lado

### UtilitÃ¡rios
- [x] Download automatizado do VoxCeleb1
- [x] GeraÃ§Ã£o de dados sintÃ©ticos
- [x] ConfiguraÃ§Ã£o via YAML
- [x] Logging estruturado

---

## ğŸ”§ ConfiguraÃ§Ãµes

Edite [config/config.yaml](config/config.yaml) para ajustar:

```yaml
data:
  n_mfcc: 40           # NÃºmero de coeficientes MFCC
  max_len: 100         # Janela temporal
  
training:
  rf:
    n_estimators: 100  # Ãrvores no Random Forest
    max_depth: 20      # Profundidade mÃ¡xima
  
  cnn:
    epochs: 50         # Ã‰pocas de treinamento
    batch_size: 32     # Tamanho do batch
    learning_rate: 0.001
```

---

## ğŸ“ˆ MÃ©tricas de Desempenho

### Tempo de Treinamento (Dataset SintÃ©tico)
- **Random Forest:** ~2 minutos
- **CNN:** ~3 minutos (50 Ã©pocas, CPU)

### Tamanho dos Modelos
- **Random Forest:** ~15 MB (random_forest.pkl)
- **CNN:** ~2 MB (cnn_modelo.h5)

### InferÃªncia
- **Random Forest:** ~0.5 ms/amostra
- **CNN:** ~2 ms/amostra (CPU)

---

## ğŸ“ Contexto AcadÃªmico

### Disciplina
- **CÃ³digo:** BCC406
- **Nome:** Redes Neurais
- **InstituiÃ§Ã£o:** [Sua Universidade]

### Objetivos de Aprendizado
1. âœ… Comparar paradigmas clÃ¡ssicos vs deep learning
2. âœ… Implementar pipeline completo de ML
3. âœ… Trabalhar com dados de Ã¡udio reais
4. âœ… Avaliar modelos criticamente
5. âœ… Documentar cÃ³digo profissionalmente

---

## ğŸ› Problemas Conhecidos

### 1. CNN com baixa acurÃ¡cia em dataset pequeno
**Causa:** Overfitting em 200 amostras  
**SoluÃ§Ã£o:** Usar VoxCeleb1 completo ou aumentar dropout

### 2. Tempo de download do VoxCeleb1
**Causa:** Dataset de 38GB  
**SoluÃ§Ã£o:** Usar dados sintÃ©ticos para testes

### 3. GPU nÃ£o detectada no TensorFlow
**Causa:** CUDA nÃ£o configurado  
**SoluÃ§Ã£o:** Usar Colab (GPU gratuita) ou treinar em CPU

---

## ğŸ“‹ Checklist de Reprodutibilidade

- [x] Seeds fixos (numpy, tensorflow, random)
- [x] Ambiente virtual documentado
- [x] DependÃªncias versionadas (requirements.txt)
- [x] Dados sintÃ©ticos fornecidos
- [x] Scripts de download automatizados
- [x] ConfiguraÃ§Ãµes externalizadas (YAML)
- [x] Logs estruturados
- [x] Modelos salvos em formatos padrÃ£o

---

## ğŸ”— Links Importantes

### Datasets
- [VoxCeleb1 Oficial](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/)
- [Paper Original](https://arxiv.org/abs/1706.08612)

### ReferÃªncias TeÃ³ricas
- [MFCCs Explained](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum)
- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees)
- [1D CNNs for Audio](https://towardsdatascience.com/cnns-for-audio-classification-6244954665ab)

---

## ğŸ“ Suporte

### DÃºvidas Frequentes
Consulte a seÃ§Ã£o **"Problemas Comuns"** no [README.md](README.md)

### DocumentaÃ§Ã£o
Navegue pelo [INDICE.md](INDICE.md) para encontrar qualquer informaÃ§Ã£o

### Issues
Abra uma issue no repositÃ³rio para reportar bugs ou sugerir melhorias

---

## ğŸ“… HistÃ³rico

| Data | VersÃ£o | MudanÃ§as |
|------|--------|----------|
| [DATA] | 1.0 | VersÃ£o inicial com RF e CNN |
| [DATA] | 1.1 | AdiÃ§Ã£o de dados sintÃ©ticos |
| [DATA] | 1.2 | TraduÃ§Ã£o completa para PT-BR |
| [DATA] | 1.3 | OrganizaÃ§Ã£o final da documentaÃ§Ã£o |

---

## ğŸ† ConclusÃµes

### Aprendizados Principais
1. **Random Forest** Ã© superior em datasets pequenos (~200 amostras)
2. **CNN** precisa de grande volume de dados (>10k amostras)
3. **MFCCs** sÃ£o features robustas para Ã¡udio
4. **Pipeline modular** facilita experimentaÃ§Ã£o

### Trabalhos Futuros
- [ ] Treinar com VoxCeleb1 completo
- [ ] Implementar LSTM para sequÃªncias
- [ ] Testar Transformers (wav2vec 2.0)
- [ ] Criar interface web para demonstraÃ§Ã£o
- [ ] Adicionar data augmentation
- [ ] Testar em outros datasets (CommonVoice, LibriSpeech)

---

<div align="center">

**ğŸ“ Projeto BCC406 - Redes Neurais**  
*Random Forest vs CNN para IdentificaÃ§Ã£o de Falantes*

[README](README.md) | [DocumentaÃ§Ã£o](INDICE.md) | [Guia RÃ¡pido](GUIA_RAPIDO.md)

</div>
