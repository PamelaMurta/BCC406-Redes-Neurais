{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["# Notebook 02: Feature Extraction\n\n## Objectives\n1. Load preprocessed audio data\n2. Extract MFCCs, pitch, and spectral features\n3. Generate both sequential and aggregated features\n4. Save features for model training"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["import sys\nsys.path.append('..')\n\nfrom src.utils.helpers import load_config, set_random_seeds\nfrom src.data.preprocessing import preprocess_audio_for_features\nfrom src.features.audio_features import extract_all_features, pad_features_to_max_length\nfrom src.features.feature_aggregation import aggregate_features\nfrom src.data.dataset import SpeakerDataset, FeatureDataset\nimport numpy as np\nfrom tqdm import tqdm\n\n# Load config\nconfig = load_config('../config/config.yaml')\nset_random_seeds(config['seeds']['numpy'])"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Load dataset and split\ndataset = SpeakerDataset(config['dataset']['data_dir'])\ntrain_files, train_labels, val_files, val_labels, test_files, test_labels = dataset.split_dataset(\n    train_ratio=config['splits']['train'],\n    val_ratio=config['splits']['val'],\n    test_ratio=config['splits']['test'],\n    random_state=config['seeds']['numpy']\n)"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Extract features for each split\ndef extract_dataset_features(audio_files, labels, config):\n    sequential_features = []\n    aggregated_features = []\n    \n    for audio_file in tqdm(audio_files):\n        # Preprocess\n        audio, sr = preprocess_audio_for_features(audio_file, config)\n        \n        # Extract features\n        features = extract_all_features(audio, sr, config['features'])\n        \n        # Sequential (for CNN)\n        seq_feat = pad_features_to_max_length(\n            features['sequential'],\n            max_frames=config['preprocessing']['padding']['max_frames']\n        )\n        sequential_features.append(seq_feat)\n        \n        # Aggregated (for RF)\n        agg_feat = aggregate_features(seq_feat, config['aggregation']['statistics'])\n        aggregated_features.append(agg_feat)\n    \n    return np.array(sequential_features), np.array(aggregated_features), np.array(labels)"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Extract all features\nprint('Extracting training features...')\nX_train_seq, X_train_agg, y_train = extract_dataset_features(train_files, train_labels, config)\n\nprint('Extracting validation features...')\nX_val_seq, X_val_agg, y_val = extract_dataset_features(val_files, val_labels, config)\n\nprint('Extracting test features...')\nX_test_seq, X_test_agg, y_test = extract_dataset_features(test_files, test_labels, config)"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Save features\nimport h5py\nimport pickle\nfrom pathlib import Path\n\nPath(config['dataset']['processed_dir']).mkdir(parents=True, exist_ok=True)\n\n# Save sequential features (for CNN)\nwith h5py.File(f\"{config['dataset']['processed_dir']}/train_sequential.h5\", 'w') as f:\n    f.create_dataset('features', data=X_train_seq)\n    f.create_dataset('labels', data=y_train)\n\nwith h5py.File(f\"{config['dataset']['processed_dir']}/val_sequential.h5\", 'w') as f:\n    f.create_dataset('features', data=X_val_seq)\n    f.create_dataset('labels', data=y_val)\n\nwith h5py.File(f\"{config['dataset']['processed_dir']}/test_sequential.h5\", 'w') as f:\n    f.create_dataset('features', data=X_test_seq)\n    f.create_dataset('labels', data=y_test)\n\n# Save aggregated features (for RF)\nwith open(f\"{config['dataset']['processed_dir']}/train_aggregated.pkl\", 'wb') as f:\n    pickle.dump({'features': X_train_agg, 'labels': y_train}, f)\n\nwith open(f\"{config['dataset']['processed_dir']}/val_aggregated.pkl\", 'wb') as f:\n    pickle.dump({'features': X_val_agg, 'labels': y_val}, f)\n\nwith open(f\"{config['dataset']['processed_dir']}/test_aggregated.pkl\", 'wb') as f:\n    pickle.dump({'features': X_test_agg, 'labels': y_test}, f)\n\nprint('Features saved successfully!')"]
    }
  ],
  "metadata": {
    "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
